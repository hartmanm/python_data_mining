#!/bin/bash
# for University_of_Illinois 2021
# Michael Neill Hartman

# store the number of lines in dataset
NUMBER_OF_LINES=$(wc -l dataset | awk '{print $1}')
NUMBER_OF_LINES=$(($NUMBER_OF_LINES))

# generate a modified_dataset with space IFS from dataset
cat dataset | tr ' ' '_' | tr ';' ' ' > modified_dataset

# make a result file
> result

# populate result file
ITERATOR=1
while [[ $ITERATOR -lt $NUMBER_OF_LINES+1 ]]
do
LINE=$(head -$ITERATOR modified_dataset | tail -1)
for TOKEN in ${LINE}
do
# exclude instances of token as a sub-token, find instances of token, count instances, format output to first field, translate from single token to original string, write to file
echo "`grep -v "_${TOKEN}" modified_dataset | grep "${TOKEN}" | wc -l | awk '{print $1}'`:`echo ${TOKEN} | tr '_' ' '`" >> result
done ## for TOKEN in ${LINE}

[[ $(($ITERATOR % 1000)) -eq 0 ]] && {
echo "$ITERATOR/$NUMBER_OF_LINES"
} ## [[ $(($ITERATOR % 1000)) -eq 0 ]] && {
ITERATOR=$(($ITERATOR+1))
done ## while [[ $ITERATOR -lt $NUMBER_OF_LINES+1 ]]

# sort in numerical order then remove duplicates
sort -n result | uniq > final_result

# remove all blank lines
perl -i -n -e "print if /\S/" final_result

# remove all support < 771
NUMBER_OF_LINES=$(wc -l final_result | awk '{print $1}')
NUMBER_OF_LINES=$(($NUMBER_OF_LINES))
FROM_BOTTOM=$(($NUMBER_OF_LINES-771))
tail -$FROM_BOTTOM final_result > patterns.txt 

# remove all blank lines
perl -i -n -e "print if /\S/" patterns.txt 

# run with:  time bash apriori | tee log

# 92m17.769s

echo "
complete; result in: patterns.txt
"
