#!/bin/bash
# for University_of_Illinois 2021
# Michael Neill Hartman

# store the number of lines in dataset
NUMBER_OF_LINES=$(wc -l dataset | awk '{print $1}')
NUMBER_OF_LINES=$(($NUMBER_OF_LINES))

# generate a modified_dataset with space IFS from dataset
cat dataset | tr ' ' '_' | tr ';' ' ' > modified_dataset

# make a result file
> result

# populate result file
ITERATOR=1
while [[ $ITERATOR -lt $NUMBER_OF_LINES+1 ]]
do
LINE=$(head -$ITERATOR modified_dataset | tail -1)
for TOKEN in ${LINE}
do
SUPPORT=""
SUPPORT=`grep -v "_${TOKEN}" modified_dataset | grep "${TOKEN}" | wc -l | awk '{print $1}'`
[[ `echo ${SUPPORT}` != "" ]] && SUPPORT=$(($SUPPORT*1))
echo "${SUPPORT}:`echo ${TOKEN} | tr '_' ' '`" >> result
done ## for TOKEN in ${LINE}

[[ $(($ITERATOR % 1000)) -eq 0 ]] && {
echo "$ITERATOR/$NUMBER_OF_LINES"
} ## [[ $(($ITERATOR % 1000)) -eq 0 ]] && {
ITERATOR=$(($ITERATOR+1))
done ## while [[ $ITERATOR -lt $NUMBER_OF_LINES+1 ]]

# remove duplicates
sort -n result | uniq > patterns.txt 

# remove all unused support lines from final_result
#sed -r '/^\s*$/d' final_result > patterns.txt

# remove all blank lines from final
perl -i -n -e "print if /\S/" patterns.txt 

# run with:  time bash apriori | tee log

# 92m17.769s

echo "
complete; result in: patterns.txt
"
