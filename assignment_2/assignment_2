
#!/bin/bash
# for University_of_Illinois 2021
# Michael Neill Hartman

# assumes file i/o performed on ramdisk

SOURCE_FILE=reviews_sample.txt

PART_1=0 # generate a file of all tokens
         # generates part1
PART_2=0 # find support for each token in tokens, and store those with greater than 100 in patterns.txt in the format support:token
         # generates part2
PART_3=1 # for edge case 1: for each token from part2 determine if it occurs more than once in a line or only once
         # and write the results to two files only_one / gt_one respectively
RESTARTING_PART_3=0 # when restarting part_3 with partial results dont wipe only_one or gt_one 
         # generates part3,only_one,gt_one
PART_4=0 # generate file of all lines with tokens from part2
         # generates part4
PART_5=0 # generate file with all two token sequences using part4 for basis and part 2 for tokens
         # and and store them in the format support:token as part5
         # generates part5


NUMBER_OF_LINES=$(wc -l ${SOURCE_FILE} | awk '{print $1}')
NUMBER_OF_LINES=$(($NUMBER_OF_LINES+1))


[[ $PART_1 -eq 1 ]] && {
# generate a file of all tokens

# list to store unique tokens
TOKENS=""

# iterate over each line
ITERATOR=1
while [[ $ITERATOR -lt ${NUMBER_OF_LINES} ]]
do
LINE=$(head -$ITERATOR ${SOURCE_FILE} | tail -1)

# process tokens in line
NUMBER_OF_TOKENS_IN_LINE=$(echo ${LINE} | awk '{print NF}')
NUMBER_OF_TOKENS_IN_LINE=$(($NUMBER_OF_TOKENS_IN_LINE*1))
while [[ $NUMBER_OF_TOKENS_IN_LINE -gt 0 ]]
do
THIS=$(echo "$LINE" | awk -v i=$NUMBER_OF_TOKENS_IN_LINE '{print $i}')

# append token to $TOKENS if it is unique
[[ `echo ${TOKENS} | grep ${THIS}` == "" ]] && TOKENS="${TOKENS} ${THIS}"

NUMBER_OF_TOKENS_IN_LINE=$(($NUMBER_OF_TOKENS_IN_LINE-1))
done ## while [[ $NUMBER_OF_TOKENS_IN_LINE -gt 0 ]]

# output progess feedback
ITERATOR=$(($ITERATOR+1))
[[ $(($ITERATOR % 100)) -eq 0 ]] && {
echo "
$ITERATOR 
"
} ## [[ $(($ITERATOR % 100)) -eq 0 ]] && {
done ## while [[ $ITERATOR -lt ${NUMBER_OF_LINES} ]]

# store TOKENS in the file tokens
> tokens
for ITEM in ${TOKENS}
do
echo ${ITEM} >> tokens
done ## for ITEM in ${TOKENS}
cp tokens part1
} ## [[ $PART_1 -eq 1 ]] && {


[[ $PART_2 -eq 1 ]] && {
# find support for each token in tokens, and store those with greater than 100 in patterns.txt in the format support:token
> patterns.txt
ITERATOR=1
for ITEM in `cat tokens`
do
SUPPORT=$(grep -c ${ITEM} ${SOURCE_FILE})
SUPPORT=$(($SUPPORT*1))
[[ $SUPPORT -gt 99 ]] && echo "${SUPPORT}:${ITEM}" >> patterns.txt

# output progess feedback
ITERATOR=$(($ITERATOR+1))
[[ $(($ITERATOR % 100)) -eq 0 ]] && {
echo "
$ITERATOR 
"
} ## [[ $(($ITERATOR % 100)) -eq 0 ]] && {
done ## for ITEM in `cat tokens`
cp patterns.txt part2
} ## [[ $PART_2 -eq 1 ]] && {


[[ $PART_3 -eq 1 ]] && {
# for edge case 1: for each token from part2 determine if it occurs more than once in a line or only once
# and write the results to two files only_one / gt_one respectively
> part3

# extract only token names from part2 and write them as a list to part3
PART_2_TOKENS=$(cat part2 | tr ':' ' ' | awk '{print $2}')
echo ${PART_2_TOKENS} > part3
echo "extract only token names from part2 and write them as a list to part3 complete!"

## when restarting with partial results dont wipe only_one or gt_one
[[ $RESTARTING_PART_3 -eq 1 ]] && {
> only_one
> gt_one
} ## [[ $RESTARTING_PART_3 -eq 1 ]] && {
[[ ! -e only_one ]] && > only_one
[[ ! -e gt_one ]] && > gt_one

## iterate over results using results limiting and tail
for ITEM in ${PART_2_TOKENS}
do
# find all lines matching ITEM and write them to temp
> temp
grep ${ITEM} reviews_sample.txt > temp

# find the number of lines in temp
TEMP_NUMBER_OF_LINES=$(wc -l temp | awk '{print $1}')
TEMP_NUMBER_OF_LINES=$(($TEMP_NUMBER_OF_LINES+1))

# remove all lines with only 1 match
ITERATOR=1
IS_TARGET_WITH_THIS_ITEM=0
ALREADY_PROCESSED=`grep $ITEM only_one`
while [[ $ITERATOR -ne ${TEMP_NUMBER_OF_LINES}+1 ]]
do
# skip 
[[ ${ALREADY_PROCESSED} == "" ]] && {
RESULT=$(cat temp | head -$ITERATOR | tail -1)
IS_ONE=$(echo ${RESULT} | grep -c ${ITEM})
IS_ONE=$(($IS_ONE*1))
echo "
${ITEM}
$ITERATOR / $TEMP_NUMBER_OF_LINES
$IS_ONE
${IS_TARGET_WITH_THIS_ITEM}
"
[[ $IS_ONE -gt 1 ]] && {
echo "${IS_ONE}:${ITEM}" >> gt_one
IS_TARGET_WITH_THIS_ITEM=1
} ## [[ $IS_ONE -gt 1 ]] && {
} ## [[ ${ALREADY_PROCESSED} == "" ]] && {
ITERATOR=$(($ITERATOR+1))
done ## while [[ $ITERATOR -ne ${TEMP_NUMBER_OF_LINES}+1 ]]

[[ $IS_TARGET_WITH_THIS_ITEM -eq 0 ]] && echo "$ITEM" >> only_one

echo "$ITEM gt 1 is: $IS_TARGET_WITH_THIS_ITEM, $ITEM complete!"
done ## for ITEM in ${PART_2_TOKENS}

cat gt_one > part3
} ## [[ $PART_3 -eq 1 ]] && {


[[ $PART_4 -eq 1 ]] && {
 # generate file of all lines with tokens from part2
> part4

# extract only token names from part2 and write them as a list to part3
PART_2_TOKENS=$(cat part2 | tr ':' ' ' | awk '{print $2}')
echo ${PART_2_TOKENS} > temp
echo "extract only token names from part2 and write them as a list to temp complete!"



cat temp | grep   ${SOURCE_FILE}


} ## [[ $PART_4 -eq 1 ]] && {










exec true


cat temp | head -3 | tail -1 | grep -c road


# iterate over each match of ITEM in the SOURCE_FILE line by line
LINE=$(grep -m $ITERATOR ${ITEM} ${SOURCE_FILE} | tail -1)


for ITEM_FOR_PAIR in ${PART_2_TOKENS}
do
PAIR=$(echo ${LINE} | tr ' ' '\n' | grep -c ${ITEM})


done ## for ITEM in ${PART_2_TOKENS}

# determine number of token occurances in line
#MORE_THAN_ONE=$(echo ${LINE} | tr ' ' '\n' | grep -c ${ITEM})
#MORE_THAN_ONE=$(($MORE_THAN_ONE*1))
#[[ $MORE_THAN_ONE -gt 1 ]] && echo "$MORE_THAN_ONE ${LINE}"

# determine position of target token in line
HEAD=$(echo ${LINE} | tr ' ' '\n' | grep -n ${ITEM} | tr ':' ' ' | awk '{print $1}')

# determine the length of the line
LENGTH=$(echo ${LINE} | tr ' ' '\n' | wc -l)


SUBPATTERN=$(echo ${LINE} | tr ' ' '\n' | tail -$(($LENGTH-$HEAD)) | tr '\n' ' ')


# IS_UNIQUE=$(grep -c ${SUBPATTERN} ${SOURCE_FILE})


# process tokens in line
NUMBER_OF_TOKENS_IN_LINE=$(echo ${LINE} | awk '{print NF}')
NUMBER_OF_TOKENS_IN_LINE=$(($NUMBER_OF_TOKENS_IN_LINE*1))
while [[ $NUMBER_OF_TOKENS_IN_LINE -gt 0 ]]
do
THIS_SUBPATTERN=$(echo "$LINE" | awk -v i=$NUMBER_OF_TOKENS_IN_LINE '{print $i}')
SUBPATTERN=$(echo ${LINE} | tr ' ' '\n' | tail -$(($LENGTH-$HEAD)) | tr '\n' ' ')


IS_UNIQUE=$(grep -c ${THIS_SUBPATTERN} ${SOURCE_FILE})
IS_UNIQUE=$(($IS_UNIQUE*1))
# append token to $TOKENS if it is unique
[[ $IS_UNIQUE -gt 100 ]] && echo "${SUPPORT}:${THIS_SUBPATTERN}" >> part3

NUMBER_OF_TOKENS_IN_LINE=$(($NUMBER_OF_TOKENS_IN_LINE-1))
done ## while [[ $NUMBER_OF_TOKENS_IN_LINE -gt 0 ]]



ITERATOR=$(($ITERATOR+1))


done ## for ITEM in ${PART_2_TOKENS}


# find support for each token in tokens, and store those with greater than 100 in patterns.txt in the format support:token
cat part2 > patterns.txt
for ITEM in `cat tokens`
do

SUPPORT=$(grep -c ${ITEM} tokens)
SUPPORT=$(($SUPPORT*1))
[[ $SUPPORT -gt 99 ]] && echo "${SUPPORT}:${ITEM}" >> patterns.txt
done ## for ITEM in `cat tokens`

cat part3
} ## [[ $PART_ -eq 1 ]] && {
