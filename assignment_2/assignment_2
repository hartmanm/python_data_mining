
#!/bin/bash
# for University_of_Illinois 2021
# Michael Neill Hartman

# assumes file i/o performed on ramdisk

START_AT=1

SOURCE_FILE=reviews_sample.txt

PART_1=0 # generate a file of all tokens
         # generates part1
PART_2=0 # find support for each token in tokens, and store those with greater than 100 in patterns.txt in the format support:token
         # generates part2
## note no PART_3 edge cases, no need to run
        PART_3=0 # for edge case 1: for each token from part2 determine if it occurs more than once in a line or only once
         # and write the results to two files only_one / gt_one respectively
        RESTARTING_PART_3=0 # when restarting part_3 with partial results dont wipe only_one or gt_one 
         # generates part3,only_one,gt_one
PART_4=0 # generate file of all lines with tokens from part2
         # generates part4
PART_5=1 # remove duplicate lines from part4
         # generates part5           
PART_6=0 # generate file with all two token sequences using part5 for basis and part 2 for tokens
         # and and store them in the format support:token as part6
         # generates part6


NUMBER_OF_LINES=$(wc -l ${SOURCE_FILE} | awk '{print $1}')
NUMBER_OF_LINES=$(($NUMBER_OF_LINES+1))


[[ $PART_1 -eq 1 ]] && {
# generate a file of all tokens

# list to store unique tokens
TOKENS=""

# iterate over each line
ITERATOR=1
while [[ $ITERATOR -lt ${NUMBER_OF_LINES} ]]
do
LINE=$(head -$ITERATOR ${SOURCE_FILE} | tail -1)

# process tokens in line
NUMBER_OF_TOKENS_IN_LINE=$(echo ${LINE} | awk '{print NF}')
NUMBER_OF_TOKENS_IN_LINE=$(($NUMBER_OF_TOKENS_IN_LINE*1))
while [[ $NUMBER_OF_TOKENS_IN_LINE -gt 0 ]]
do
THIS=$(echo "$LINE" | awk -v i=$NUMBER_OF_TOKENS_IN_LINE '{print $i}')

# append token to $TOKENS if it is unique
[[ `echo ${TOKENS} | grep ${THIS}` == "" ]] && TOKENS="${TOKENS} ${THIS}"

NUMBER_OF_TOKENS_IN_LINE=$(($NUMBER_OF_TOKENS_IN_LINE-1))
done ## while [[ $NUMBER_OF_TOKENS_IN_LINE -gt 0 ]]

# output progess feedback
ITERATOR=$(($ITERATOR+1))
[[ $(($ITERATOR % 100)) -eq 0 ]] && {
echo "
$ITERATOR 
"
} ## [[ $(($ITERATOR % 100)) -eq 0 ]] && {
done ## while [[ $ITERATOR -lt ${NUMBER_OF_LINES} ]]

# store TOKENS in the file tokens
> tokens
for ITEM in ${TOKENS}
do
echo ${ITEM} >> tokens
done ## for ITEM in ${TOKENS}
cp tokens part1
} ## [[ $PART_1 -eq 1 ]] && {


[[ $PART_2 -eq 1 ]] && {
# find support for each token in tokens, and store those with greater than 100 in patterns.txt in the format support:token
> patterns.txt
ITERATOR=1
for ITEM in `cat tokens`
do
SUPPORT=$(grep -c ${ITEM} ${SOURCE_FILE})
SUPPORT=$(($SUPPORT*1))
[[ $SUPPORT -gt 99 ]] && echo "${SUPPORT}:${ITEM}" >> patterns.txt

# output progess feedback
ITERATOR=$(($ITERATOR+1))
[[ $(($ITERATOR % 100)) -eq 0 ]] && {
echo "
$ITERATOR 
"
} ## [[ $(($ITERATOR % 100)) -eq 0 ]] && {
done ## for ITEM in `cat tokens`
cp patterns.txt part2
} ## [[ $PART_2 -eq 1 ]] && {


[[ $PART_3 -eq 1 ]] && {
# for edge case 1: for each token from part2 determine if it occurs more than once in a line or only once
# and write the results to two files only_one / gt_one respectively
> part3

# extract only token names from part2 and write them as a list to part3
PART_2_TOKENS=$(cat part2 | tr ':' ' ' | awk '{print $2}')
echo ${PART_2_TOKENS} > part3
echo "extract only token names from part2 and write them as a list to part3 complete!"

## when restarting with partial results dont wipe only_one or gt_one
[[ $RESTARTING_PART_3 -eq 1 ]] && {
> only_one
> gt_one
} ## [[ $RESTARTING_PART_3 -eq 1 ]] && {
[[ ! -e only_one ]] && > only_one
[[ ! -e gt_one ]] && > gt_one

## iterate over results using results limiting and tail
for ITEM in ${PART_2_TOKENS}
do
# find all lines matching ITEM and write them to temp
> temp
grep ${ITEM} reviews_sample.txt > temp

# find the number of lines in temp
TEMP_NUMBER_OF_LINES=$(wc -l temp | awk '{print $1}')
TEMP_NUMBER_OF_LINES=$(($TEMP_NUMBER_OF_LINES+1))

# remove all lines with only 1 match
ITERATOR=1
IS_TARGET_WITH_THIS_ITEM=0
ALREADY_PROCESSED=`grep $ITEM only_one`
while [[ $ITERATOR -ne ${TEMP_NUMBER_OF_LINES}+1 ]]
do
# skip 
[[ ${ALREADY_PROCESSED} == "" ]] && {
RESULT=$(cat temp | head -$ITERATOR | tail -1)
IS_ONE=$(echo ${RESULT} | grep -c ${ITEM})
IS_ONE=$(($IS_ONE*1))
echo "
${ITEM}
$ITERATOR / $TEMP_NUMBER_OF_LINES
$IS_ONE
${IS_TARGET_WITH_THIS_ITEM}
"
[[ $IS_ONE -gt 1 ]] && {
echo "${IS_ONE}:${ITEM}" >> gt_one
IS_TARGET_WITH_THIS_ITEM=1
} ## [[ $IS_ONE -gt 1 ]] && {
} ## [[ ${ALREADY_PROCESSED} == "" ]] && {
ITERATOR=$(($ITERATOR+1))
done ## while [[ $ITERATOR -ne ${TEMP_NUMBER_OF_LINES}+1 ]]

[[ $IS_TARGET_WITH_THIS_ITEM -eq 0 ]] && echo "$ITEM" >> only_one

echo "$ITEM gt 1 is: $IS_TARGET_WITH_THIS_ITEM, $ITEM complete!"
done ## for ITEM in ${PART_2_TOKENS}

cat gt_one > part3
} ## [[ $PART_3 -eq 1 ]] && {


[[ $PART_4 -eq 1 ]] && {
 # generate file of all lines with tokens from part2
> part4

# extract only token names from part2 and write them as a list to part3
PART_2_TOKENS=$(cat part2 | tr ':' ' ' | awk '{print $2}')
echo ${PART_2_TOKENS} > temp
echo "extract only token names from part2 and write them as a list to temp complete!"

# find all lines matching ITEM and write them to temp if they aren't in temp already
> temp
NUMBER_OF_PART_2_TOKENS=$(echo ${PART_2_TOKENS} | wc | awk '{print $2}')
THIS_TOKEN=1
for ITEM in ${PART_2_TOKENS}
do
grep ${ITEM} reviews_sample.txt > temp2
# find the number of lines in temp2
TEMP_NUMBER_OF_LINES=$(wc -l temp2 | awk '{print $1}')
TEMP_NUMBER_OF_LINES=$(($TEMP_NUMBER_OF_LINES+1))
ITERATOR=1
while [[ $ITERATOR -ne ${TEMP_NUMBER_OF_LINES}+1 ]]
do
LINE=$(cat temp2 | head -$ITERATOR | tail -1)
IS_ALREADY=$(grep -c "${LINE}" temp)
[[ "${IS_ALREADY}" == "0" ]] && echo "${LINE}" >> temp
ITERATOR=$(($ITERATOR+1))
done ## while [[ $ITERATOR -ne ${TEMP_NUMBER_OF_LINES}+1 ]]
echo "
$THIS_TOKEN / $NUMBER_OF_PART_2_TOKENS
"
THIS_TOKEN=$(($THIS_TOKEN+1))
done ## for ITEM in ${PART_2_TOKENS}
cat temp > part4
} ## [[ $PART_4 -eq 1 ]] && {






[[ $PART_5 -eq 1 ]] && {
> part5
# begin processing line at passed value from START_AT
ITERATOR=$START_AT
while [[ $ITERATOR -ne $NUMBER_OF_LINES+1 ]]
do
LINE=$(cat ${SOURCE_FILE} | head -$ITERATOR | tail -1)
# process tokens in line
# see if the entire line has a support of > 100
# (see if line - last token has a support of > 100) until all tokens in line have been tested
NUMBER_OF_TOKENS_IN_LINE=$(echo ${LINE} | awk '{print NF}')
NUMBER_OF_TOKENS_IN_LINE=$(($NUMBER_OF_TOKENS_IN_LINE*1))
while [[ $NUMBER_OF_TOKENS_IN_LINE -gt 0 ]]
do
#THIS_SUBPATTERN=$(echo "$LINE" | awk -v i=$NUMBER_OF_TOKENS_IN_LINE '{print $(NF-i)}')
THIS_SUBPATTERN=$(echo "$LINE" | tr ' ' '\n' | head -$NUMBER_OF_TOKENS_IN_LINE | tr '\n' ' ')

IS_UNIQUE=$(grep -c "${THIS_SUBPATTERN}" ${SOURCE_FILE})
IS_UNIQUE=$(($IS_UNIQUE*1))
# append token to $TOKENS if it is unique
[[ $IS_UNIQUE -gt 100 ]] && {
FORMATTED=`echo ${THIS_SUBPATTERN} | tr ' ' ';'`
IS_ALREADY=$(grep -c "${IS_UNIQUE}:${THIS_SUBPATTERN}" part5)
[[ "${IS_ALREADY}" == "0" ]] && {
echo "${IS_UNIQUE}:${FORMATTED}" >> part5
} ## [[ "${IS_ALREADY}" == "0" ]] && {
} ## [[ $IS_UNIQUE -gt 100 ]] && {
NUMBER_OF_TOKENS_IN_LINE=$(($NUMBER_OF_TOKENS_IN_LINE-1))
done ## while [[ $NUMBER_OF_TOKENS_IN_LINE -gt 0 ]]
echo "
$ITERATOR / $NUMBER_OF_LINES
"
ITERATOR=$(($ITERATOR+1))
done ## while [[ $ITERATOR -ne $NUMBER_OF_LINES+1 ]]
} ## [[ $PART_5 -eq 1 ]] && {



exec true





















#uniq part4 part5
#} ## [[ $PART_5 -eq 1 ]] && {

#exec true
#cat temp | head -3 | tail -1 | grep -c road


# extract only token names from part2 and write them as a list to part3
PART_2_TOKENS=$(cat part2 | tr ':' ' ' | awk '{print $2}')
echo ${PART_2_TOKENS} > temp
echo "extract only token names from part2 and write them as a list to temp complete!"

NUMBER_OF_PART_2_TOKENS=$(echo ${PART_2_TOKENS} | wc | awk '{print $2}')
THIS_TOKEN=1
for ITEM in ${PART_2_TOKENS}
do



# iterate over each match of ITEM in the SOURCE_FILE line by line
ITERATOR=1
grep ${ITEM} ${SOURCE_FILE} > lines
LINE=$(cat lines | head -1)
#LINE=$(grep -m $ITERATOR ${ITEM} ${SOURCE_FILE} | tail -1)
while [[ "${LINE}" != "${LAST_LINE}" ]]
do
LINE=$(cat lines | head -$ITERATOR | tail -1)
ITERATOR=$(($ITERATOR+1))
[[ "${LINE}" != "" ]] && LAST_LINE=${LINE}
done ## while [[ "${LINE}" != "${LAST_LINE}" ]]




echo "
$THIS_TOKEN / $NUMBER_OF_PART_2_TOKENS
"
THIS_TOKEN=$(($THIS_TOKEN+1))
done ## for ITEM in ${PART_2_TOKENS}






NUMBER_OF_PART_2_TOKENS=$(echo ${PART_2_TOKENS} | wc | awk '{print $2}')
THIS_TOKEN=1
for ITEM in ${PART_2_TOKENS}
do
grep ${ITEM} reviews_sample.txt > temp2


TEMP_NUMBER_OF_LINES=$(wc -l temp2 | awk '{print $1}')
TEMP_NUMBER_OF_LINES=$(($TEMP_NUMBER_OF_LINES+1))
ITERATOR=1
while [[ $ITERATOR -ne ${TEMP_NUMBER_OF_LINES}+1 ]]
do
LINE=$(cat temp2 | head -$ITERATOR | tail -1)
IS_ALREADY=$(grep -c "${LINE}" temp)
[[ "${IS_ALREADY}" == "0" ]] && echo "${LINE}" >> temp
ITERATOR=$(($ITERATOR+1))
done ## while [[ $ITERATOR -ne ${TEMP_NUMBER_OF_LINES}+1 ]]








echo "
$THIS_TOKEN / $NUMBER_OF_PART_2_TOKENS
"
THIS_TOKEN=$(($THIS_TOKEN+1))
done ## for ITEM in ${PART_2_TOKENS}




} ## [[ $PART_5 -eq 1 ]] && {





exec true


for ITEM_FOR_PAIR in ${PART_2_TOKENS}
do
PAIR=$(echo ${LINE} | tr ' ' '\n' | grep -c ${ITEM})


done ## for ITEM in ${PART_2_TOKENS}

# determine number of token occurances in line
#MORE_THAN_ONE=$(echo ${LINE} | tr ' ' '\n' | grep -c ${ITEM})
#MORE_THAN_ONE=$(($MORE_THAN_ONE*1))
#[[ $MORE_THAN_ONE -gt 1 ]] && echo "$MORE_THAN_ONE ${LINE}"

# determine position of target token in line
HEAD=$(echo ${LINE} | tr ' ' '\n' | grep -n ${ITEM} | tr ':' ' ' | awk '{print $1}')

# determine the length of the line
LENGTH=$(echo ${LINE} | tr ' ' '\n' | wc -l)


SUBPATTERN=$(echo ${LINE} | tr ' ' '\n' | tail -$(($LENGTH-$HEAD)) | tr '\n' ' ')


# IS_UNIQUE=$(grep -c ${SUBPATTERN} ${SOURCE_FILE})


# process tokens in line
NUMBER_OF_TOKENS_IN_LINE=$(echo ${LINE} | awk '{print NF}')
NUMBER_OF_TOKENS_IN_LINE=$(($NUMBER_OF_TOKENS_IN_LINE*1))
while [[ $NUMBER_OF_TOKENS_IN_LINE -gt 0 ]]
do
THIS_SUBPATTERN=$(echo "$LINE" | awk -v i=$NUMBER_OF_TOKENS_IN_LINE '{print $i}')
#SUBPATTERN=$(echo ${LINE} | tr ' ' '\n' | tail -$(($LENGTH-$HEAD)) | tr '\n' ' ')


IS_UNIQUE=$(grep -c ${THIS_SUBPATTERN} ${SOURCE_FILE})
IS_UNIQUE=$(($IS_UNIQUE*1))
# append token to $TOKENS if it is unique
[[ $IS_UNIQUE -gt 100 ]] && echo "${SUPPORT}:${THIS_SUBPATTERN}" >> part3

NUMBER_OF_TOKENS_IN_LINE=$(($NUMBER_OF_TOKENS_IN_LINE-1))
done ## while [[ $NUMBER_OF_TOKENS_IN_LINE -gt 0 ]]



ITERATOR=$(($ITERATOR+1))


done ## for ITEM in ${PART_2_TOKENS}


# find support for each token in tokens, and store those with greater than 100 in patterns.txt in the format support:token
cat part2 > patterns.txt
for ITEM in `cat tokens`
do

SUPPORT=$(grep -c ${ITEM} tokens)
SUPPORT=$(($SUPPORT*1))
[[ $SUPPORT -gt 99 ]] && echo "${SUPPORT}:${ITEM}" >> patterns.txt
done ## for ITEM in `cat tokens`

cat part3
} ## [[ $PART_ -eq 1 ]] && {
